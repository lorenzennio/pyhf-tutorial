{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PID weights and uncertainties\n",
    "\n",
    "Here we calculate the PID effects by comparing data and MC for certain benchmark channels. For this we use the [systematics framework](https://syscorrfw.readthedocs.io/en/latest/index.html).\n",
    "\n",
    "Fist we will obtain the PID corrwction tables, with uncertainties, then we will apply the weights to the ntuples and lastly we calculate the systematics table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction tables\n",
    "\n",
    "This code will only run on KEKCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML \n",
    "\n",
    "# Path to scripts on KEKCC\n",
    "sys_path = '/group/belle2/dataprod/Systematics/systematic_corrections_framework/scripts'\n",
    "\n",
    "sys.path.insert(1, sys_path)\n",
    "\n",
    "sys.path.append('/group/belle2/dataprod/Systematics/systematic_corrections_framework')\n",
    "\n",
    "import efficiency_table as et\n",
    "import process_tables as pt\n",
    "import show_db_content as sdb\n",
    "import id_vs_misid_curve as roc\n",
    "import weight_table as wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_cfg = {\n",
    "    \"cut\": \"kaonID > 0.9\",\n",
    "    \"particle_type\": \"K\", #pi - efficiency max 5%\n",
    "    \"data_collection\": \"proc13+prompt\",\n",
    "    \"mc_collection\": \"MC15ri\",\n",
    "    \"track_variables\": [\"p\", \"cosTheta\"],\n",
    "    \"precut\": \"nCDCHits > 20\",\n",
    "    \"binning\": [list(np.linspace(0.5, 4.5, 11)), \n",
    "                [-0.866, -0.682, -0.4226, -0.1045, 0.225, 0.5, 0.766, 0.8829, 0.9563]],\n",
    "}\n",
    "efficiency = wm.produce_data_mc_ratio(**ratio_cfg)\n",
    "\n",
    "efficiency_table_K = efficiency.create_weights()\n",
    "# Uncomment the following line to see the content \n",
    "# of the produced weight table in pandas DataFrame format:\n",
    "\n",
    "efficiency_table_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_cfg = {\n",
    "    \"cut\": \"kaonID > 0.9\",\n",
    "    \"particle_type\": \"pi\", #pi - efficiency max 5%\n",
    "    \"data_collection\": \"proc13+prompt\",\n",
    "    \"mc_collection\": \"MC15ri\",\n",
    "    \"track_variables\": [\"p\", \"cosTheta\"],\n",
    "    \"precut\": \"nCDCHits > 20\",\n",
    "    \"binning\": [list(np.linspace(0.5, 4.5, 11)), \n",
    "                [-0.866, -0.682, -0.4226, -0.1045, 0.225, 0.5, 0.766, 0.8829, 0.9563]],\n",
    "}\n",
    "efficiency = wm.produce_data_mc_ratio(**ratio_cfg)\n",
    "\n",
    "efficiency_table_pi = efficiency.create_weights()\n",
    "# Uncomment the following line to see the content \n",
    "# of the produced weight table in pandas DataFrame format:\n",
    "\n",
    "efficiency_table_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_table_K.to_csv('pid-tables/efficiency_table_K.csv')\n",
    "efficiency_table_pi.to_csv('pid-tables/efficiency_table_pi.csv')\n",
    "\n",
    "efficiency_table_K = pd.from_csv('pid-tables/efficiency_table_K.csv')\n",
    "efficiency_table_pi = pd.from_csv('pid-tables/efficiency_table_pi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PID weights\n",
    "\n",
    "This code will only run on KEKCC, as the corresponding samples are there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path('/home/belle2/lorenzg/pyhf-tutorial/ntuples_reconstructed')\n",
    "ntuples = {\n",
    "    'data_ssbar'    : {BASE / 'MC15ri_b_Kpi0_generic_200fb_8/ssbar.root': 'Bsig'},\n",
    "    'data_ccbar'    : {BASE / 'MC15ri_b_Kpi0_generic_200fb_8/ccbar.root': 'Bsig'},\n",
    "    'data_charged'  : {BASE / 'MC15ri_b_Kpi0_generic_200fb_8/charged.root': 'Bsig'},\n",
    "    'data_mixed'    : {BASE / 'MC15ri_b_Kpi0_generic_200fb_8/mixed.root': 'Bsig'},\n",
    "    'signal'        : {BASE / 'MC15ri_b_Kpi0_signal_8/00.root': 'Bsig'},\n",
    "    'signal_rmt'    : {BASE / 'MC15ri_b_Kpi0_signal_rmT_4/sub00/grid_00000_job348357260_00.root': 'Bsig'},\n",
    "    'ssbar'         : {BASE / 'MC15ri_b_Kpi0_generic_200fb_9/ssbar.root' : 'Bsig'},\n",
    "    'ssbar_rmt'     : {BASE / 'MC15ri_b_Kpi0_generic_200fb_9/ssbar_rmT.root': 'Bsig'},\n",
    "    'ccbar'         : {BASE / 'MC15ri_b_Kpi0_generic_200fb_9/ccbar.root' : 'Bsig'},\n",
    "    'ccbar_rmt'     : {BASE / 'MC15ri_b_Kpi0_generic_200fb_9/ccbar_rmT.root': 'Bsig'},\n",
    "    'charged'       : {BASE / 'MC15ri_b_Kpi0_generic_200fb_9/charged.root': 'Bsig'},\n",
    "    'charged_rmt'   : {BASE / 'MC15ri_b_Kpi0_generic_200fb_9/charged_rmT.root': 'Bsig'},\n",
    "    'mixed'         : {BASE / 'MC15ri_b_Kpi0_generic_200fb_9/mixed.root': 'Bsig'},\n",
    "    'mixed_rmt'     : {BASE / 'MC15ri_b_Kpi0_generic_200fb_9/mixed_rmT.root': 'Bsig'},\n",
    "    'misID'         : {BASE / 'MC15ri_b_Kpi0_misID/misID.root': 'Bsig'},\n",
    "    'misID_rmt'     : {BASE / 'MC15ri_b_Kpi0_misID/misID_rmT.root': 'Bsig'}    \n",
    "}\n",
    "\n",
    "cols = ['__production__', 'B_isSignal', 'B_deltaE', 'K_mcPDG',  'K_p', 'K_theta', 'B_R2', 'B_cosTBTO', 'B_mcErrors']\n",
    "pid_cols = ['data_MC_ratio',\n",
    "            'data_MC_uncertainty_stat_up', 'data_MC_uncertainty_stat_dn',\n",
    "            'data_MC_uncertainty_sys_up', 'data_MC_uncertainty_sys_dn']\n",
    "uproot.open({BASE / 'MC15ri_b_Kpi0_signal_8/00.root': 'Bsig'}).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(p, th, eff, var):\n",
    "    costh = np.cos(th)\n",
    "    return eff.query('@p >= p_min and @p < p_max and @costh >= cosTheta_min and @costh < cosTheta_max')[var]\n",
    "\n",
    "nK = 0\n",
    "npi= 0\n",
    "\n",
    "kPDG = 321\n",
    "piPDG = 211\n",
    "\n",
    "for k,v in ntuples.items():\n",
    "    df = uproot.concatenate(v, cols, library='pd')\n",
    "\n",
    "    rows = [[row['K_p'], row['K_theta'], row['K_mcPDG']] for _, row in df.iterrows()]\n",
    "    \n",
    "    pid_weights = pd.DataFrame(data=None, columns=pid_cols)\n",
    "    for r in rows:\n",
    "        if np.abs(r[2]) == kPDG:\n",
    "            nK += 1\n",
    "            w = get_weight(r[0], r[1], efficiency_table_K, pid_cols)\n",
    "        elif np.abs(r[2]) == piPDG:\n",
    "            npi += 1\n",
    "            w = get_weight(r[0], r[1], efficiency_table_pi, pid_cols)\n",
    "        else:\n",
    "            w = pd.DataFrame(data=[[1,0,0,0,0]], columns=pid_cols)\n",
    "        pid_weights  = pd.concat([pid_weights, w], ignore_index=True, sort=False)\n",
    "        \n",
    "    for v in pid_cols:\n",
    "        df[v] = pid_weights[v]\n",
    "    \n",
    "    # add total uncertainty\n",
    "    unc = np.sqrt(((pid_weights[pid_cols[1]].astype(float)+pid_weights[pid_cols[2]].astype(float))/2.)**2 \n",
    "                    + ((pid_weights[pid_cols[3]].astype(float)+pid_weights[pid_cols[4]].astype(float))/2.)**2)\n",
    "    df['PID_total_uncertainty'] = unc\n",
    "        \n",
    "    print(k, df.info())\n",
    "    with uproot.recreate(f'ntuples/{k}.root') as file:\n",
    "        file['B'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nK, npi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating systematic corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBin(df, var, bins):\n",
    "    '''\n",
    "        Determine bin numbers for the 2D->1D\n",
    "        Input:\n",
    "            df: input dataframe (or lazyarray)\n",
    "            binning: bin edges of the fitting binning\n",
    "        Output:\n",
    "           np.array of 2D bin numbers. For entries outside bin boundaries, returns 0 or len1*len2+1.\n",
    "\n",
    "        Example usage:\n",
    "           dSig = getBin2D(sig[sig.bdt_v24_ff_weights>0.9],'B_sig_K_pt__vs__bdt_v24_ff_weights_T09')\n",
    "           h = plt.hist(dSig[(dSig>0)&(dSig<13)],13,(1.,13.))\n",
    "    '''\n",
    "    # 1-d digitize:\n",
    "    out = np.digitize(df[var], bins)\n",
    "    return out\n",
    "\n",
    "\n",
    "def identify_mc_category(prod_id):\n",
    "    ''' Identify a MC category from a production number\n",
    "    '''\n",
    "    if prod_id in [25052] :\n",
    "        return 'signal'\n",
    "    elif prod_id in [24787, 24797] :\n",
    "        return 'qqbar'\n",
    "    elif prod_id in [24817, 24822]:\n",
    "        return 'BBbar'\n",
    "    elif prod_id in [26308]:\n",
    "        return 'misID'\n",
    "\n",
    "    else:\n",
    "        warnings.warn(f\"{prod_id} category unknown.\")\n",
    "        return 'unknown'\n",
    "    \n",
    "v_category = np.vectorize(identify_mc_category)\n",
    "\n",
    "class PIDstatErrorPropagator:\n",
    "    '''\n",
    "       Class to compute covariance matrix for PID stat. uncertainties.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, df, bins, varStat, nrep=500):\n",
    "        '''\n",
    "           Input variables:\n",
    "              df   : mc sample. Should include all productions (signal + backgrounds)\n",
    "              bins: bin edges of the fitting binning\n",
    "              varStat : PID stat. error\n",
    "              nrep : number of toy MC replica\n",
    "        '''\n",
    "        keys = set(np.nan_to_num(df[varStat]))\n",
    "        self.df = df\n",
    "        self.bins = bins\n",
    "        self.len = len(keys)\n",
    "        self.varStat = varStat\n",
    "        self.nrep = nrep\n",
    "        print(\"len=\", self.len)\n",
    "        self.toys = dict()\n",
    "        for key in keys:\n",
    "            toy = np.random.lognormal(0., min(key, 1.), nrep)\n",
    "            self.toys[key] = toy\n",
    "\n",
    "    def getW(self):\n",
    "        ''' Return array of weight uncertainties for each event\n",
    "            Output:\n",
    "              out :  array ( len(df),  self.nrep ) of weight errors per event\n",
    "        '''\n",
    "        a = np.nan_to_num(np.array(self.df[self.varStat]))\n",
    "        out = np.zeros((len(a), self.nrep))\n",
    "        for i in range(len(a)):\n",
    "            out[i] = self.toys[a[i]]\n",
    "        return out\n",
    "\n",
    "    def cov(\n",
    "        self,\n",
    "        var,\n",
    "        prods=[\n",
    "            'signal',\n",
    "            'qqbar',\n",
    "            'BBbar',\n",
    "            'misID']):\n",
    "        '''\n",
    "            Compute covariance matrix for df and fit bins\n",
    "\n",
    "            Input variables:\n",
    "               var : variable name in variable_registry\n",
    "               prods : event categories\n",
    "\n",
    "            Output:\n",
    "               av    : sum of weights for each bin, each event category.\n",
    "                       Dimention of av is given by Ncategories x Nbins\n",
    "               cov   : covariance matrix\n",
    "               prods : same as input (useful if default value is used)\n",
    "        '''\n",
    "        prod = v_category(self.df.__production__)\n",
    "        www = self.getW()\n",
    "        dSig = getBin(self.df, var, self.bins)\n",
    "        nbin = len(self.bins)-1\n",
    "        # over bins\n",
    "        out = np.zeros((nbin*len(prods), self.nrep))\n",
    "        for j, p in enumerate(prods):\n",
    "            for i in range(nbin):\n",
    "                out[j*nbin+i] = np.sum(www[(dSig == i+1) & (p == prod)], axis=0)\n",
    "\n",
    "        av = np.average(out, axis=1)\n",
    "        dd = out-av[:, np.newaxis]\n",
    "        cov = np.sum(dd[np.newaxis, :, :]*dd[:, np.newaxis, :], axis=2)/self.nrep\n",
    "        return av, cov, prods\n",
    "    \n",
    "def covToNui(cov):\n",
    "    '''\n",
    "    Perform decoposition of covariance matrix cov\n",
    "\n",
    "    Input variables:\n",
    "        cov : covariance matrix\n",
    "    Output variables:\n",
    "        vec : eigenvectors, ordered with most significant being the last\n",
    "    '''\n",
    "    va, ve = np.linalg.eigh(cov)\n",
    "    diag = np.identity(len(va))\n",
    "    va = np.where(va > 0, va, 0)\n",
    "    sva = np.sqrt(va)*diag\n",
    "    pa = ve.dot(sva)  # error vectors, to use with \"nuisance parameters\"\n",
    "    return np.transpose(pa)\n",
    "\n",
    "def truncateNui(vec, n):\n",
    "    '''\n",
    "    Keep only N most significant eigenvectors, cut the rest\n",
    "\n",
    "    Input variables:\n",
    "        vec : input eigenvectors\n",
    "        n   : number of eigenvectors to keep\n",
    "\n",
    "    Output:\n",
    "        dia  : uncorrelated part, to be added to stat. uncertainty in quadrature\n",
    "        ovec : remaining correlated eigenvectors\n",
    "    '''\n",
    "    s = vec.shape[0]\n",
    "    ovec = vec[s-n:s]\n",
    "    odia = vec[:s-n]\n",
    "    dia = np.sqrt(np.sum(odia**2, axis=0))\n",
    "    return dia, ovec\n",
    "\n",
    "def check_array(x):\n",
    "    try:\n",
    "        x.shape\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def dumpSyst(dia, ovec, cent, names, fname):\n",
    "    '''\n",
    "        Store results in a csv file.\n",
    "\n",
    "        Input variables:\n",
    "           dia  : array of uncorrelated uncertainties (or None)\n",
    "           ovec : matrix of correlated eigenvectors\n",
    "           cent : central values\n",
    "           names: names of categories\n",
    "           fname: output file name\n",
    "        Output:\n",
    "           creates a comma separated table \"fname\"\n",
    "           column \"type\" has value \"u\" for uncorrelated and \"c\" for correlated uncertainty\n",
    "           other colums encode bin/category info, e.g.  \"signal_10\"\n",
    "    '''\n",
    "    isDia = check_array(dia)\n",
    "    \n",
    "    if isDia == False:\n",
    "        pass\n",
    "    else:\n",
    "        d = np.where(cent > 0, dia/cent, 0)\n",
    "    v = np.where(cent > 0, ovec/cent, 0)\n",
    "\n",
    "    ln = len(names)\n",
    "    if isDia == False:\n",
    "        lo = ovec.shape[1]\n",
    "    else:\n",
    "        lo = len(dia)\n",
    "    lb = lo // ln\n",
    "    with open(fname, \"w\") as f:\n",
    "        s = \"type\"\n",
    "        for n in names:\n",
    "            for b in range(lb):\n",
    "                s += \",{}_{}\".format(n, b+1)\n",
    "        f.write(s+\"\\n\")\n",
    "\n",
    "        if isDia:\n",
    "            f.write(\"u,\" + \",\".join([\"{:6.3f}\".format(d) for d in d*100]) + \"\\n\")\n",
    "        if (len(v.shape) > 1): \n",
    "            for i,vv in enumerate(v[:]):\n",
    "                f.write(\"c{},\".format(i+1) + \",\".join([\"{:6.3f}\".format(d) for d in vv*100]) + \"\\n\")\n",
    "        else:\n",
    "            f.write(\"c,\" + \",\".join([\"{:6.3f}\".format(d) for d in v*100]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = ['signal', 'ssbar', 'ccbar', 'charged', 'mixed', 'misID']\n",
    "cols = ['__production__', 'B_isSignal', 'B_deltaE', 'K_mcPDG',  'K_p', 'K_theta', 'B_R2', 'B_cosTBTO', 'B_mcErrors']\n",
    "files = [{f'ntuples/{p}.root':'B'} for p in productions]\n",
    "all = uproot.concatenate(files, cols+pid_cols+['PID_total_uncertainty'], library='pd')\n",
    "all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-0.4, 0.4, 20 + 1)\n",
    "pid = PIDstatErrorPropagator(all, bins, varStat='PID_total_uncertainty', nrep=500)\n",
    "\n",
    "sigAv, sigCov, pnames = pid.cov('B_deltaE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = covToNui(sigCov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "_labels = {'signal': 'signal', 'qqbar': 'qqbar', 'BBbar': 'BBbar', 'misID': 'misID'}\n",
    "\n",
    "N = 5\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,5))\n",
    "di = np.diag(sigCov)\n",
    "rr = np.sqrt(di[np.newaxis,:]*di[:,np.newaxis])\n",
    "ra = np.where(rr>0,sigCov/rr,0)\n",
    "im = ax[0].imshow(ra,vmin=-0.2,vmax=1,origin='lower')\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax[0].set_xticks(np.arange(0,80,20))\n",
    "ax[0].set_xticklabels([_labels[p] for p in pnames], rotation=45)\n",
    "ax[0].set_yticks(np.arange(0,80,20))\n",
    "ax[0].set_yticklabels([_labels[p] for p in pnames], rotation=0)\n",
    "ax[0].set_xlabel('Bin number')\n",
    "ax[0].set_ylabel('Bin number')\n",
    "\n",
    "d,v =truncateNui(vec,N)\n",
    "cov2 = np.transpose(v).dot(v) +np.identity(len(d))*d**2\n",
    "\n",
    "di = np.diag(cov2)\n",
    "rr = np.sqrt(di[np.newaxis,:]*di[:,np.newaxis])\n",
    "ra = np.where(rr>0,cov2/rr,0)\n",
    "im = ax[1].imshow(ra,vmin=-0.2,vmax=1,origin='lower')\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax[1].set_xticks(np.arange(0,80,20))\n",
    "ax[1].set_xticklabels([_labels[p] for p in pnames], rotation=45) #45\n",
    "ax[1].set_yticks(np.arange(0,80,20))\n",
    "ax[1].set_yticklabels([_labels[p] for p in pnames], rotation=0)\n",
    "ax[1].set_xlabel('Bin number')\n",
    "ax[1].set_ylabel('Bin number')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.patch.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpSyst(d, v, sigAv, pnames, 'pid-tables/pid_systematics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
